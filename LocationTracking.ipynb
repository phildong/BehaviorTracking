{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "The following code was designed in order to track the location of a single animal across the course of a session.  After initally loading in the video, the user is able to crop the video frame using a rectangle selection tool.  A background reference frame is then specified, either by taking a median of several frames in the video, or by the user providing a short video of the same environment without an animal in it.  By comparing each frame in the video to the reference frame, the location of the animal can be tracked.  It is imperative that the reference frame of the video is not shifted from the actual video.  For this reason, if a separate video is supplied, it is best that it be acquired on the same day as the behavioral recording.  The location of the animal (it's center of mass, or COM) in x,y coordinates is then recorded, as well as the distance in pixels that the animal moves from one frame to the next. Lastly, the user can specify regions of interest in the frame (e.g. left, right) using a polygon drawing tool and record for each frame whether the animal is in the region of interest.  Options for summarizing the data are also provided. \n",
    "\n",
    "### Package Requirements\n",
    "Please see instructions under repository README for package requirements and install instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Load Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import LocationTracking_Functions as lt\n",
    "import holoviews as hv\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. User Sets Directory and File Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Windows Users:*** Place an 'r' in front directory path (e.g. r\"zp\\Videos\") to avoid mishandling of forward slashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dict = {\n",
    "    'dpath' : \"/Users/zachpennington/Desktop/Videos\", # directory containing file\n",
    "    'file' : \"SF2-0training5session2-2Merged.avi\", #filename with extension\n",
    "    'fps' : 30, #frames per second\n",
    "    'start' : 500, #frame at which to start. 0-based\n",
    "    'end' : 10000 #frame at which to end.  set to None if processing whole video.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Load Video and Crop Frame if Desired\n",
    "To crop video frame, after running code below, select box selection tool below image (square with a plus sign).  To start drawing region to be included in analyis, double click image.  Double click again to finalize region.  If you decide to change region, it is best to rerun this cell and subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "#Select output size if image is too small/large.  Code above must be first line in cell and dictates overall size\n",
    "#of image, where 100 is standard.  \n",
    "\n",
    "#stretch image size if desired\n",
    "stretch ={\n",
    "    'width' : 1 , #Default=1. Can be used to stretch image width if needed \n",
    "    'height' : 1 #Default=1. Can be used to stretch image width if needed \n",
    "}\n",
    "\n",
    "#Load image to allow cropping.  Returned item 'crop' is a HoloViews stream object.\n",
    "image,crop,video_dict=lt.LoadAndCrop(video_dict,stretch,cropmethod='Box')\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Define Reference Frame for Location Tracking\n",
    "For location tracking to work, view of box without animal must be provided.  Below there are two ways to do this.  **Option 1** provides a method to remove the animal from the video.  This option works well provided the animal doesn't stay in the same location the whole time. Alternatively, with **Option 2**, the user can simply define a video file in the same folder that doesn't have in animal in it.  Option 1 is generally recormmended for this reason.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 - Create reference frame by removing animal from video\n",
    "The following code takes 100 random frames across the session and creates an average of them by taking the median for each pixel.  This will remove influence of animal on any given frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Reference Frame\n",
    "reference = lt.Reference(video_dict,crop,num_frames=100) \n",
    "\n",
    "#Display Reference Frame\n",
    "scale=1 #scale image as desired\n",
    "image = hv.Image((np.arange(reference.shape[1]), np.arange(reference.shape[0]), reference))\n",
    "image.opts(width=int(reference.shape[1]*scale),\n",
    "           height=int(reference.shape[0]*scale),\n",
    "           invert_yaxis=True,cmap='gray',toolbar='below',\n",
    "           title=\"Reference Frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - User specifies video of empty box\n",
    "The following code allows the user to specify a different file.  Notably, an average is still taken of multiple frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User selects file\n",
    "video_dict['altfile'] = 'SF2-0test2-2Merged.avi' #specify filename of video in dpath directory (e.g. 'Video1.mpg')\n",
    "\n",
    "#Create Reference Frame\n",
    "reference = lt.Reference(video_dict,crop,num_frames=100) \n",
    "\n",
    "#Display Reference Frame\n",
    "scale=1 #scale image as desired\n",
    "image = hv.Image((np.arange(reference.shape[1]), np.arange(reference.shape[0]), reference))\n",
    "image.opts(width=int(reference.shape[1]*scale),\n",
    "           height=int(reference.shape[0]*scale),\n",
    "           invert_yaxis=True,cmap='gray',toolbar='below',\n",
    "           title=\"Reference Frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Track Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Set Location Tracking Parameters\n",
    "Location tracking examines the deviance of each frame in a video from the reference frame on a pixel by pixel basis.  For each frame it calculates the center of mass for these differences (COM) to define the center of the animal.  \n",
    "\n",
    "In order to improve accuracy, the parameter loc_thresh is used to remove the influence of pixels that are minimally different from the reference frame.  For each frame relative to the reference frame, the distribution of absolute difference values across pixels is examined and only values above loc_thresh percentile are considered.  I have been using 99 and this works well.  Values can range from 0-100 and floating point numbers are fine.\n",
    "\n",
    "The parameters use_window, window, and window_weight are employed to reduce the chance that any objects other than the animal  that might enter the frame (e.g. the hand of the experimenter) influence location tracking.  For each frame, a square window with the animal's position on the prior frame at its center is given more weight when searching for it's location (because an animal presumably can't move far in a fraction of a second).  When window_weight is set to 1, pixels outside of the window are not considered at all; at 0, they are given equal weight.  Notably, setting a high value (e.g. 0.9) should allow the program to more rapidly find the animal if by chance it moves out of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_params = {\n",
    "    'loc_thresh' : 99,\n",
    "    'use_window' : True, #True/False.  Will window surrounding prior location be imposed?\n",
    "    'window_size' : 100, #The length of one side of square window.  \n",
    "    'window_weight' : 0, #0-1 scale, where 1 is maximal weight of window surrounding prior locaiton.\n",
    "    'SIGMA' : 1, #this is sigma used for gaussian smoothing of image. 1 works well.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Display Examples of Location Tracking to Confirm Threshold\n",
    "In order to confirm threshold is working a subset of images is analyzed and displayed using the selected loc_thresh.  The original image is displayed on top and the difference scores are presented below.  The center of mass (COM) is pinpointed on images.  Notably, because individual frames are used, window settings are not applicable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 2 #number of examples to display\n",
    "\n",
    "figsize=(15,10) #figure size\n",
    "lt.LocationThresh_View(examples,figsize,video_dict,reference,crop,tracking_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Track Location and Save Results to .csv File\n",
    "For each frame the location of the animal's center of mass is recorded in x,y coordinates.  Frame-by-frame distance is also calculated in pixel units.  This data is returned in a Pandas dataframe with columns: frame, x, y, dist.  Data is saved to a .csv in the same folder as the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=lt.TrackLocation(video_dict,tracking_params,reference,crop)\n",
    "\n",
    "#Set output name and save\n",
    "location.to_csv(os.path.splitext(video_dict['fpath'])[0] + '_LocationOutput.csv')\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5d. Display Animal Location Across Session\n",
    "Below, animals distance, x, and y coordinates across the sessin are plotted.  Smooth traces are expected in the case where they animal is tracked consistently across the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "\n",
    "#Plot Distance Across Session\n",
    "w, h = 900,300 #specify width and heigh of plot\n",
    "dist_plot = hv.Curve((location['Frame'],location['Distance']),'Frame','Pixel Distance').opts(height=h,width=w,color='blue',title=\"Distance\",toolbar=\"below\")\n",
    "dist_plot\n",
    "\n",
    "#Plot \n",
    "scale=1 #scale overlay as desired\n",
    "image = hv.Image((np.arange(reference.shape[1]), np.arange(reference.shape[0]), reference)).opts(\n",
    "    width=int(reference.shape[1]*scale),\n",
    "    height=int(reference.shape[0]*scale),\n",
    "    invert_yaxis=True,cmap='gray',toolbar='below',\n",
    "    title=\"Motion Trace\")\n",
    "points = hv.Scatter(np.array([location['X'],location['Y']]).T).opts(color='navy',alpha=.2)\n",
    "tracks = image*points\n",
    "\n",
    "(dist_plot+tracks).cols(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. (Optional) Analyze Activity of Animal in Region of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. User Supplies Names of Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = [\"Left\",\"Right\"] # e.g. region_names = [\"Left\",\"Right\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Use Interactive Plot to Define Regions of Interest.  Supports Polygons. \n",
    "Draw regions of interest in the order you provided them.  To start drawing a region, double click on image.  Single click to add a vertex.  Double click to close polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "#Select output size if image is too small/large.  Code above must be first line in cell and dictates overall size\n",
    "#of image, where 100 is standard.  \n",
    "\n",
    "#stretch image size if desired\n",
    "stretch ={\n",
    "    'width' : 1 , #Default=1. Can be used to stretch image width if needed \n",
    "    'height' : 1 #Default=1. Can be used to stretch image width if needed \n",
    "}\n",
    "\n",
    "plot,poly_stream = lt.ROI_plot(reference,region_names,stretch)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Define ROI Containing Animal for Each Frame and Save Output File as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = lt.ROI_Location(reference,poly_stream,region_names,location)\n",
    "\n",
    "#Set output name and save\n",
    "location.to_csv(os.path.splitext(video_dict['fpath'])[0] + '_LocationOutput.csv')\n",
    "location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. (Optional) Create Binned Summary Report and Save\n",
    "The code below allows user to either save a csv containing summary data for user-defined bins (e.g. freezing in each minute) or a session-wide average.\n",
    "\n",
    "To specify bins, set bin_dict using the following notation, where start and stop represent time in seconds:\n",
    "\n",
    "```\n",
    "bin_dict = {\n",
    "    'BinName1': (start, stop),\n",
    "    'BinName2': (start, stop),\n",
    "    'BinName3': (start, stop),\n",
    "}\n",
    "```\n",
    "\n",
    "***If you only want a session avg***, set bin_dict = {}\n",
    "\n",
    "***If you are not using ROIs***, set value of 'region_names' within function to None in code below (region_names=None).  Otherwise, keep region_names=region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dict = {\n",
    "    1: (0, 60),\n",
    "    2: (60, 120),\n",
    "    3: (120, 180),\n",
    "    4: (180, 240),\n",
    "    5: (240, 300)\n",
    "}\n",
    "summary = lt.Summarize_Location(location, video_dict, bin_dict=bin_dict, region_names=region_names)\n",
    "summary.to_csv(os.path.splitext(video_dict['fpath'])[0] + '_SummaryStats.csv')\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
